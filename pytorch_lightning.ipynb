{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkeodev/pytorch-tutorial/blob/main/pytorch_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9fde7e",
      "metadata": {
        "id": "5e9fde7e"
      },
      "source": [
        "# PyTorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df83c04f",
      "metadata": {
        "id": "df83c04f"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning is a high-level framework that builds on top of PyTorch, one of the most popular deep learning libraries. It's designed to decouple the science code from the engineering code, helping researchers and developers focus on the core aspects of their models by abstracting away the boilerplate code typically associated with model training, validation, and testing. This approach not only makes the code more readable and maintainable but also significantly speeds up the development process for complex deep learning projects."
      ],
      "metadata": {
        "id": "VlH9H6QTJjD5"
      },
      "id": "VlH9H6QTJjD5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Advantages of Using PyTorch Lightning Over Plain PyTorch"
      ],
      "metadata": {
        "id": "QmO4nSgCEKES"
      },
      "id": "QmO4nSgCEKES"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "1. **Reduced Boilerplate Code**: PyTorch Lightning automates much of the setup code needed in PyTorch, such as training loops, validation loops, and testing loops, allowing developers to focus on the model's architecture and data rather than the mechanics of the training process.\n",
        "\n",
        "2. **Reproducibility**: It ensures experiments are more reproducible by standardizing the way models are trained. This is achieved through a structured framework that encourages best practices and reduces the chances of making errors.\n",
        "\n",
        "3. **Scalability**: PyTorch Lightning simplifies the process of scaling your models to run on more GPUs, TPUs, or across multiple nodes. This makes it easier to scale your experiments without having to deeply understand distributed computing.\n",
        "\n",
        "4. **Flexibility**: Despite the high-level abstractions, PyTorch Lightning offers flexibility, allowing advanced users to customize the training loop and other components when needed. This means you can start with the simple, high-level interface and dive deeper as your project's complexity grows.\n",
        "\n",
        "5. **Built-in Advanced Features**: PyTorch Lightning comes with many advanced features out of the box, such as support for mixed precision training, which can significantly speed up computations and reduce memory usage, and automatic checkpointing, which makes it easy to save and resume training sessions.\n",
        "\n",
        "6. **Community and Ecosystem**: PyTorch Lightning has a vibrant and growing community, with a wide range of plugins and integrations available. This ecosystem includes support for popular tools and platforms, making it easier to incorporate things like logging, monitoring, and model serving into your workflow.\n",
        "\n",
        "In summary, PyTorch Lightning is designed to make deep learning projects simpler, faster, and more efficient, without sacrificing the power and flexibility that PyTorch provides. By abstracting away the engineering details, it enables researchers and developers to allocate more time to the scientific aspects of their projects, resulting in faster experimentation and development cycles."
      ],
      "metadata": {
        "id": "sjJZzsEpJKvW"
      },
      "id": "sjJZzsEpJKvW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "O7YPSaRN_aCy"
      },
      "id": "O7YPSaRN_aCy"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch_lightning -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDedC1Y0_dUE",
        "outputId": "510d3cbb-8559-497e-b515-1331e49594dc"
      },
      "id": "mDedC1Y0_dUE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m681.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, DistributedSampler, random_split\n",
        "import torch.distributed as dist\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "ieV9lcyQ_-Bc"
      },
      "id": "ieV9lcyQ_-Bc",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d19ef3c6",
      "metadata": {
        "id": "d19ef3c6"
      },
      "source": [
        "## Core Concepts of PyTorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightningModule"
      ],
      "metadata": {
        "id": "dRTW-kgGKaHq"
      },
      "id": "dRTW-kgGKaHq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `LightningModule` is a central concept in PyTorch Lightning, acting as a comprehensive encapsulation of the PyTorch `nn.Module`. It serves as the backbone for organizing your model's computations, including the forward pass, and it also integrates the training, validation, and testing steps within a single class. This approach significantly simplifies the model development process by structuring the code in a way that separates the computational part of the model from the experimental setup.\n",
        "\n",
        "A `LightningModule` defines:\n",
        "- **Model Architecture**: How the inputs are processed to produce outputs, encapsulated in the `forward` method.\n",
        "- **Training Step**: The logic for a single iteration in the training loop, including forward pass, loss calculation, and backpropagation.\n",
        "- **Validation and Testing Steps**: Procedures for evaluating the model on validation and test datasets to monitor performance and prevent overfitting.\n",
        "- **Optimizers and Schedulers**: Configuration of optimizers and learning rate schedulers, specifying how weights are updated and how the learning rate changes over time.\n",
        "\n",
        "By integrating these aspects into a unified class, `LightningModule` streamlines model development, making the code more modular, easier to read, and maintain, while also promoting best practices in deep learning research and development."
      ],
      "metadata": {
        "id": "wTe1llG-KNqe"
      },
      "id": "wTe1llG-KNqe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainer"
      ],
      "metadata": {
        "id": "86hHiKMQKXDs"
      },
      "id": "86hHiKMQKXDs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Trainer` in PyTorch Lightning is a powerful engine that abstracts the complexity of writing the training loop and integrates your PyTorch code with the rich ecosystem of PyTorch Lightning features. It is responsible for managing the training process, including running the training, validation, and testing loops, handling device placement (CPU, GPU, TPU), and facilitating distributed training.\n",
        "\n",
        "Key features of the `Trainer` include:\n",
        "- **Automatic Training Loop**: It automates the training process, managing everything from the start of training to its conclusion, including calling the appropriate steps defined in the `LightningModule`.\n",
        "- **Checkpointing**: Automatically saves and, if needed, resumes the model's state from a checkpoint, ensuring long experiments can be paused and restarted without loss of progress.\n",
        "- **Logging and Monitoring**: Integrates with popular logging and visualization tools (e.g., TensorBoard, MLFlow), enabling easy tracking of experiments and model performance.\n",
        "- **Distributed Training**: Simplifies scaling up your training to multiple GPUs, TPUs, or nodes without the need to deeply understand the underlying distributed computing frameworks."
      ],
      "metadata": {
        "id": "wuYxOrGNKQPi"
      },
      "id": "wuYxOrGNKQPi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataModule"
      ],
      "metadata": {
        "id": "Cwwwdtg3KUQS"
      },
      "id": "Cwwwdtg3KUQS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DataModule` is a data handling class that abstracts the complexity of data loading, preparation, and preprocessing in PyTorch Lightning. It allows for a clean separation of data-related logic from the modeling code, making datasets reusable and shareable across projects.\n",
        "\n",
        "A `DataModule` typically defines:\n",
        "- **Data Preparation**: The steps to download, tokenize, and process the data.\n",
        "- **Data Loaders**: Configuration of the PyTorch `DataLoader` for the training, validation, and test datasets, facilitating batched and optionally parallel data loading.\n",
        "- **Transforms**: Any data augmentation or preprocessing operations that should be applied to the data before it is passed to the model.\n",
        "\n",
        "By encapsulating data-related tasks, the `DataModule` promotes a more organized and modular approach to handling datasets in PyTorch projects, making it easier to adapt to new data sources or experiment with different preprocessing techniques."
      ],
      "metadata": {
        "id": "ovmk_pbfKILt"
      },
      "id": "ovmk_pbfKILt"
    },
    {
      "cell_type": "markdown",
      "id": "6010c9fc",
      "metadata": {
        "id": "6010c9fc"
      },
      "source": [
        "## Key Features of PyTorch Lightning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Automation of Common Training Procedures"
      ],
      "metadata": {
        "id": "P7cwLphJKmbg"
      },
      "id": "P7cwLphJKmbg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning\n"
      ],
      "metadata": {
        "id": "PCbZXKJG9V3e"
      },
      "id": "PCbZXKJG9V3e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In standard PyTorch, setting up a training loop requires manually coding the entire process, including forward passes, calculating loss, backpropagation, and updating model parameters."
      ],
      "metadata": {
        "id": "0McjqDnW9aWs"
      },
      "id": "0McjqDnW9aWs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 128)\n",
        "        self.layer2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.functional.relu(self.layer1(x))\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Load data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize network and optimizer\n",
        "model = SimpleNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10): # train for 10 epochs\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYBpfDYu9gSY",
        "outputId": "1f1b7927-2814-4de7-a253-d8b90f94aef2"
      },
      "id": "uYBpfDYu9gSY",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 148260703.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 22650653.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 132227432.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14323705.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Epoch 0, Loss: 0.14844422042369843\n",
            "Epoch 1, Loss: 0.1093560978770256\n",
            "Epoch 2, Loss: 0.10502023249864578\n",
            "Epoch 3, Loss: 0.19714826345443726\n",
            "Epoch 4, Loss: 0.010195491835474968\n",
            "Epoch 5, Loss: 0.13798223435878754\n",
            "Epoch 6, Loss: 0.02335546910762787\n",
            "Epoch 7, Loss: 0.23562780022621155\n",
            "Epoch 8, Loss: 0.004139881581068039\n",
            "Epoch 9, Loss: 0.005697409622371197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning"
      ],
      "metadata": {
        "id": "jWvnln1O_EAx"
      },
      "id": "jWvnln1O_EAx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning automates the training process, requiring you to define the training step, and it handles the rest."
      ],
      "metadata": {
        "id": "k-sFePoa_GhM"
      },
      "id": "k-sFePoa_GhM"
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningNet(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(LightningNet, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 128)\n",
        "        self.layer2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.functional.relu(self.layer1(x))\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        output = self(images)\n",
        "        loss = nn.CrossEntropyLoss()(output, labels)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "# Data module for organizing data loading\n",
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "    def train_dataloader(self):\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "        train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "        return DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Setup model and data module\n",
        "model = LightningNet()\n",
        "mnist_data = MNISTDataModule()\n",
        "\n",
        "# Train model\n",
        "trainer = pl.Trainer(max_epochs=10)\n",
        "trainer.fit(model, mnist_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "244b30e11b304ec68c4b64e4b8f051ee",
            "8c1cd7937492468b80728072f9bf9a77",
            "44be3743f9094f97b36f3eb6b3b2fd97",
            "06a69b9ffe324bc5b596150d01a534ac",
            "0c192f2541a24729a32d5bee92a7c788",
            "4f266305f163404db0fbe1429a5915b2",
            "e6efca63e89345228b115499cb50c5c7",
            "bcf21a94c86a458085787a700f9350b8",
            "137c36098c694c7c806dc30b78343b1d",
            "431668fb199249a59a68fad4c42ebc40",
            "ef698375ce0043deae326d3edc7acdda"
          ]
        },
        "id": "asRBdiwv_Po5",
        "outputId": "f5a920a7-e9a6-4d13-b5d9-ae0efb970190"
      },
      "id": "asRBdiwv_Po5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name   | Type   | Params\n",
            "----------------------------------\n",
            "0 | layer1 | Linear | 100 K \n",
            "1 | layer2 | Linear | 1.3 K \n",
            "----------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "244b30e11b304ec68c4b64e4b8f051ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison"
      ],
      "metadata": {
        "id": "_aIBs7qsA4J9"
      },
      "id": "_aIBs7qsA4J9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Automation and Simplification**: With PyTorch Lightning, the training process is simplified as you only need to define the `training_step` and the `configure_optimizers` method. The `Trainer` object then automates the training loop, including forward and backward passes, optimization, and more.\n",
        "\n",
        "- **Reduction of Boilerplate Code**: PyTorch Lightning significantly reduces the amount of boilerplate code required, especially in training loops. This makes the code more readable and easier to maintain.\n",
        "\n",
        "- **Focus on Model and Data**: Lightning encourages a separation of concerns, allowing you to focus on the model (`LightningModule`) and data (`DataModule`) separately. This results in cleaner, more modular code that's easier to debug and extend.\n",
        "\n",
        "- **Built-in Best Practices**: PyTorch Lightning incorporates many best practices by default, such as gradient clipping and logging, reducing the chance of common mistakes and improving the efficiency of the development process."
      ],
      "metadata": {
        "id": "HdGxT6hC9J0x"
      },
      "id": "HdGxT6hC9J0x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Reproducibility\n"
      ],
      "metadata": {
        "id": "HhBvwwoCLW6J"
      },
      "id": "HhBvwwoCLW6J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning\n",
        "\n"
      ],
      "metadata": {
        "id": "LHFF0NNLBw26"
      },
      "id": "LHFF0NNLBw26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "When not using PyTorch Lightning, you would manually set seeds for all the relevant libraries you are using to ensure reproducibility. This often includes PyTorch itself, NumPy (if used for data manipulation), and Python’s random module."
      ],
      "metadata": {
        "id": "z8xyyP48By7L"
      },
      "id": "z8xyyP48By7L"
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # For CUDA-enabled GPUs\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "z_4fXsoYB3Qc"
      },
      "id": "z_4fXsoYB3Qc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning\n"
      ],
      "metadata": {
        "id": "xZUS3_MSCIfY"
      },
      "id": "xZUS3_MSCIfY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning provides a straightforward way to fix seeds across all the necessary libraries with a single line of code, ensuring reproducibility across runs."
      ],
      "metadata": {
        "id": "9s7KpkBUCKt0"
      },
      "id": "9s7KpkBUCKt0"
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxmLwfFVCRYa",
        "outputId": "8a2eb0b0-a8d5-4481-f697-edd5c56cc504"
      },
      "id": "nxmLwfFVCRYa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Easy Experiment Tracking"
      ],
      "metadata": {
        "id": "KQAms_9pCrqF"
      },
      "id": "KQAms_9pCrqF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning"
      ],
      "metadata": {
        "id": "ho0uwuLmCuhb"
      },
      "id": "ho0uwuLmCuhb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tracking experiments without PyTorch Lightning often requires manually logging metrics, model configurations, and other details to a file, a database, or a tool like TensorBoard. This can quickly become cumbersome and error-prone as the complexity of the experiments grows."
      ],
      "metadata": {
        "id": "nt9ccu2cCxQW"
      },
      "id": "nt9ccu2cCxQW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for epoch in range(10):  # Example training loop\n",
        "    # Training steps\n",
        "    # ...\n",
        "    writer.add_scalar('Loss/train', loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
        "\n",
        "writer.close()\n",
        "```"
      ],
      "metadata": {
        "id": "h41-Dfb2C3Xq"
      },
      "id": "h41-Dfb2C3Xq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning"
      ],
      "metadata": {
        "id": "IHW3KYwvC68l"
      },
      "id": "IHW3KYwvC68l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning simplifies experiment tracking and integrates seamlessly with popular tools like TensorBoard, MLFlow, Comet ML, and others. By using loggers, you can easily record metrics, hyperparameters, model graphs, and more without cluttering your model code."
      ],
      "metadata": {
        "id": "7IJFseRqDEz5"
      },
      "id": "7IJFseRqDEz5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "# Define a logger\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
        "\n",
        "# Train model with logger\n",
        "trainer = Trainer(logger=logger, max_epochs=10)\n",
        "trainer.fit(model)\n",
        "\n",
        "# Access the experiment URL if using an online logger like MLFlow, Comet ML, etc.\n",
        "print(\"Experiment URL:\", logger.experiment.url)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PP6PyT_BBrIa"
      },
      "id": "PP6PyT_BBrIa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Out-of-the-Box Support for Multi-GPU, TPU, and Distributed Training"
      ],
      "metadata": {
        "id": "FYJ4q3EqL3IK"
      },
      "id": "FYJ4q3EqL3IK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning"
      ],
      "metadata": {
        "id": "N7jvQe_dEaks"
      },
      "id": "N7jvQe_dEaks"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing multi-GPU, TPU, or distributed training in PyTorch requires a deep understanding of the underlying mechanisms like `torch.nn.DataParallel`, `torch.nn.parallel.DistributedDataParallel`, or setting up TPU environments. This process can be complex and error-prone, especially for those new to distributed computing concepts."
      ],
      "metadata": {
        "id": "qDaE4KNnEdGp"
      },
      "id": "qDaE4KNnEdGp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, DistributedSampler\n",
        "import torch.distributed as dist\n",
        "import os\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    # Model definition\n",
        "\n",
        "def train(rank, world_size):\n",
        "    setup(rank, world_size)\n",
        "    # Model, optimizer, data loader setup\n",
        "    model = MyModel()\n",
        "    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
        "    # Training loop\n",
        "    cleanup()\n",
        "\n",
        "world_size = 2\n",
        "torch.multiprocessing.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
        "```"
      ],
      "metadata": {
        "id": "lkZGabIwEm4e"
      },
      "id": "lkZGabIwEm4e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning"
      ],
      "metadata": {
        "id": "1cCJ_eLJE2SS"
      },
      "id": "1cCJ_eLJE2SS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning simplifies the process, allowing you to easily scale your models across multiple GPUs, TPUs, or nodes with minimal changes to your code. The `Trainer` class handles the complexity of distributed training.\n"
      ],
      "metadata": {
        "id": "qUPg97FeE5-w"
      },
      "id": "qUPg97FeE5-w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.plugins import DDPPlugin\n",
        "\n",
        "trainer = Trainer(\n",
        "    gpus=2,  # Number of GPUs\n",
        "    strategy=DDPPlugin(find_unused_parameters=False),  # Distributed strategy\n",
        "    precision=16,  # Mixed precision\n",
        "    accelerator='gpu'  # or 'tpu' for TPU training\n",
        ")\n",
        "\n",
        "trainer.fit(model)\n",
        "```"
      ],
      "metadata": {
        "id": "qS9_ldtrFE06"
      },
      "id": "qS9_ldtrFE06"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Integration with Popular Computing Resources and Environments"
      ],
      "metadata": {
        "id": "3znmYAbgFHyS"
      },
      "id": "3znmYAbgFHyS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning"
      ],
      "metadata": {
        "id": "M_vjPzH_FNDL"
      },
      "id": "M_vjPzH_FNDL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up your PyTorch models to run on cloud platforms (e.g., AWS, GCP, Azure) or specialized computing environments (e.g., HPC clusters) often requires a significant amount of boilerplate code and configuration. This includes managing environments, dependencies, data storage, and compute resources."
      ],
      "metadata": {
        "id": "xkcCiqFJFPK-"
      },
      "id": "xkcCiqFJFPK-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning"
      ],
      "metadata": {
        "id": "XJZRnVOYFRkw"
      },
      "id": "XJZRnVOYFRkw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning offers integrations with a variety of computing resources and environments, streamlining the process of deploying and running your models. Whether it's on a cloud provider or an HPC cluster, Lightning's Trainer and its ecosystem are designed to work seamlessly with minimal configuration."
      ],
      "metadata": {
        "id": "LOiAXdhmFWcB"
      },
      "id": "LOiAXdhmFWcB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# The same Trainer setup is used, and PyTorch Lightning takes care of the environment specifics\n",
        "trainer = Trainer(\n",
        "    gpus=2,\n",
        "    strategy='ddp',\n",
        "    precision=16,\n",
        "    accelerator='gpu'\n",
        ")\n",
        "\n",
        "trainer.fit(model)\n",
        "```"
      ],
      "metadata": {
        "id": "NAz6EkyaFZHX"
      },
      "id": "NAz6EkyaFZHX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Automatic Checkpointing and Resuming of Training"
      ],
      "metadata": {
        "id": "qt0scixoMhNs"
      },
      "id": "qt0scixoMhNs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Without PyTorch Lightning"
      ],
      "metadata": {
        "id": "rUuT8X_WGQy7"
      },
      "id": "rUuT8X_WGQy7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing automatic checkpointing and resuming in plain PyTorch requires manually saving the model and optimizer state at specific intervals and then writing additional code to load these checkpoints if training is interrupted or needs to be resumed later."
      ],
      "metadata": {
        "id": "gVyaaqArGVID"
      },
      "id": "gVyaaqArGVID"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import torch\n",
        "\n",
        "# Save checkpoint\n",
        "def save_checkpoint(model, optimizer, epoch, filepath):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, filepath)\n",
        "\n",
        "# Load checkpoint\n",
        "def load_checkpoint(filepath, model, optimizer):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return checkpoint['epoch']\n",
        "\n",
        "# Example usage\n",
        "model = ...\n",
        "optimizer = ...\n",
        "epoch_start = load_checkpoint('path_to_checkpoint.pt', model, optimizer)\n",
        "\n",
        "for epoch in range(epoch_start, num_epochs):\n",
        "    # Training loop...\n",
        "    save_checkpoint(model, optimizer, epoch, 'path_to_checkpoint.pt')\n",
        "```"
      ],
      "metadata": {
        "id": "FBurpzwNGY8W"
      },
      "id": "FBurpzwNGY8W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning"
      ],
      "metadata": {
        "id": "XJRfrY2eGbsD"
      },
      "id": "XJRfrY2eGbsD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning simplifies checkpointing and resuming. The `Trainer` class has built-in support for checkpointing, automatically saving the model, optimizer, and training state at specified intervals or based on performance metrics. Resuming is as simple as providing the checkpoint path when initializing the trainer."
      ],
      "metadata": {
        "id": "EZt_fOv1GfEb"
      },
      "id": "EZt_fOv1GfEb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# Setup model checkpointing\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss', # Monitor validation loss for checkpointing\n",
        "    dirpath='my_model/',\n",
        "    filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=3, # Save the top 3 models according to val_loss\n",
        "    mode='min', # Minimize val_loss\n",
        ")\n",
        "\n",
        "# Initialize trainer with checkpoint callback\n",
        "trainer = Trainer(\n",
        "    callbacks=[checkpoint_callback],\n",
        "    resume_from_checkpoint='my_model/model-epoch=02-val_loss=0.02.ckpt', # Optional: Path to resume from a specific checkpoint\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = ...\n",
        "trainer.fit(model)\n",
        "```"
      ],
      "metadata": {
        "id": "ogssV5gtGDA7"
      },
      "id": "ogssV5gtGDA7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Built-in Support for Mixed-Precision Training\n"
      ],
      "metadata": {
        "id": "8vzWIDpVGs39"
      },
      "id": "8vzWIDpVGs39"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PyTorch Lightning"
      ],
      "metadata": {
        "id": "6eZLa8JgGuay"
      },
      "id": "6eZLa8JgGuay"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In vanilla PyTorch, enabling mixed-precision training involves using `torch.cuda.amp` for automatic mixed precision (AMP), which can reduce memory usage and speed up training times on compatible hardware. This requires manual management of the AMP context.\n"
      ],
      "metadata": {
        "id": "UN-yYdj4Gzlc"
      },
      "id": "UN-yYdj4Gzlc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "model = ...\n",
        "optimizer = ...\n",
        "scaler = GradScaler()\n",
        "\n",
        "for inputs, labels in data_loader:\n",
        "    optimizer.zero_grad()\n",
        "    with autocast():\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "```\n"
      ],
      "metadata": {
        "id": "e6nydydfG2zN"
      },
      "id": "e6nydydfG2zN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PyTorch Lightning\n"
      ],
      "metadata": {
        "id": "rA8teHlBG6Hd"
      },
      "id": "rA8teHlBG6Hd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning offers a straightforward way to enable mixed-precision training with a single flag in the `Trainer`. This automatically handles the AMP context and scaler under the hood."
      ],
      "metadata": {
        "id": "rgaRcexLG8LY"
      },
      "id": "rgaRcexLG8LY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "# Enable mixed precision training\n",
        "trainer = Trainer(precision=16)\n",
        "\n",
        "# Train model\n",
        "model = ...\n",
        "trainer.fit(model)\n",
        "```"
      ],
      "metadata": {
        "id": "wGj3ALTtGJyq"
      },
      "id": "wGj3ALTtGJyq"
    },
    {
      "cell_type": "markdown",
      "id": "fd27d5a9",
      "metadata": {
        "id": "fd27d5a9"
      },
      "source": [
        "## Setting Up a Basic PyTorch Lightning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a basic project with PyTorch Lightning involves a few straightforward steps that help streamline the development process for deep learning models. Here's a guide to get you started:"
      ],
      "metadata": {
        "id": "IESXUD8RIEue"
      },
      "id": "IESXUD8RIEue"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Install PyTorch Lightning"
      ],
      "metadata": {
        "id": "5OSZaoo1IU8q"
      },
      "id": "5OSZaoo1IU8q"
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install pytorch-lightning -q"
      ],
      "metadata": {
        "id": "6FSQauPhIgIk"
      },
      "id": "6FSQauPhIgIk",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Define Your Model"
      ],
      "metadata": {
        "id": "uHHzQoL9I1ri"
      },
      "id": "uHHzQoL9I1ri"
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Create a Python file (e.g., `model.py`) and define your model by subclassing `pl.LightningModule`.\n",
        "   \n",
        "   Implement the required methods such as `__init__`, `forward`, `training_step`, and `configure_optimizers`."
      ],
      "metadata": {
        "id": "Atf0UD0-I6cW"
      },
      "id": "Atf0UD0-I6cW"
    },
    {
      "cell_type": "code",
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define model layers\n",
        "        self.layer = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        x = x.view(x.size(0), -1)  # Reshape input to [batch_size, 784]\n",
        "        return torch.relu(self.layer(x))\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Training logic\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = nn.functional.cross_entropy(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Optimizers\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.02)"
      ],
      "metadata": {
        "id": "zBaykWkAJECy"
      },
      "id": "zBaykWkAJECy",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Prepare Your Data"
      ],
      "metadata": {
        "id": "xO5G509oIM9J"
      },
      "id": "xO5G509oIM9J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Define your data using PyTorch's `DataLoader` or Lightning's `DataModule`.\n",
        "   \n",
        "   A `DataModule` is a shareable, reusable class that encapsulates all data loading logic."
      ],
      "metadata": {
        "id": "ECq6kTsPJV9p"
      },
      "id": "ECq6kTsPJV9p"
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Download only once\n",
        "        MNIST('data', train=True, download=True)\n",
        "        MNIST('data', train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Transform and split data\n",
        "        mnist_full = MNIST('data', train=True, transform=self.transform)\n",
        "        self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "        self.mnist_test = MNIST('data', train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=32)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=32)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.mnist_test, batch_size=32)"
      ],
      "metadata": {
        "id": "8evxBq5TJa_Q"
      },
      "id": "8evxBq5TJa_Q",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Train Your Model"
      ],
      "metadata": {
        "id": "ujJ80UeoIRnI"
      },
      "id": "ujJ80UeoIRnI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Use the `Trainer` class to train your model. Specify any configurations like the number of epochs, GPUs, etc."
      ],
      "metadata": {
        "id": "3_zwbVRwJ-bp"
      },
      "id": "3_zwbVRwJ-bp"
    },
    {
      "cell_type": "code",
      "source": [
        "model = LitModel()\n",
        "mnist_data = MNISTDataModule()\n",
        "trainer = Trainer(max_epochs=2)\n",
        "trainer.fit(model, mnist_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "1aee519a1f974e1e81350b883cb1e858",
            "a2d114d91e3640259ab33c6cdf9e3bcf",
            "6a65cbe7b0b941068f19451883137951",
            "bd12648133ee4b6994587bdd931a364e",
            "511eb6e3f9084f5d8a98fd61ca36172f",
            "220042ab36ee45eb87b50d7fe3bde23d",
            "ffc6e5dbb7ac4ee087ef7822e656702e",
            "0ff81928ba854ad0bb33f4f8385fbefb",
            "899046eb149444b69c0e15b420d91af8",
            "f9ca4a2dde6b45088f9eaeefc072945c",
            "3f36775917954b628a1fa55e4c314ff1"
          ]
        },
        "id": "etANVuPMKEU4",
        "outputId": "93ea397e-8408-45a9-f659-e36d07922a50"
      },
      "id": "etANVuPMKEU4",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type   | Params\n",
            "---------------------------------\n",
            "0 | layer | Linear | 7.9 K \n",
            "---------------------------------\n",
            "7.9 K     Trainable params\n",
            "0         Non-trainable params\n",
            "7.9 K     Total params\n",
            "0.031     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aee519a1f974e1e81350b883cb1e858"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57573c3e",
      "metadata": {
        "id": "57573c3e"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Lightning streamlines deep learning development by abstracting boilerplate code, enforcing best practices, and simplifying complexity. It supports scalable training across multiple GPUs and TPUs effortlessly, enhances reproducibility with features like fixed seeds, and remains flexible for custom needs. The active community and rich ecosystem provide extensive resources and support, making Lightning a powerful tool for efficient and reliable deep learning projects."
      ],
      "metadata": {
        "id": "4Owg4JctPSCM"
      },
      "id": "4Owg4JctPSCM"
    },
    {
      "cell_type": "markdown",
      "id": "3348edeb",
      "metadata": {
        "id": "3348edeb"
      },
      "source": [
        "## Resources and Further Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comprehensive information and resources on PyTorch Lightning, here are the key places to look:\n",
        "\n",
        "- **Documentation and Tutorials**: The [official documentation](https://pytorch-lightning.readthedocs.io/en/latest/) is a comprehensive resource for getting started with PyTorch Lightning, offering detailed guides, API references, and tutorials for users of all levels.\n",
        "  \n",
        "- **Forums and Q&A**: Platforms like the [PyTorch forums](https://discuss.pytorch.org/) and Stack Overflow have active PyTorch Lightning tags where users can ask questions, share insights, and find solutions to common (and uncommon) problems.\n",
        "  \n",
        "- **Slack Community**: PyTorch Lightning has an [official Slack community](https://pytorch-lightning.slack.com/) where developers can engage in discussions, ask for help, and share their experiences with the framework. It's a great place to stay connected with the latest news and developments in the PyTorch Lightning ecosystem.\n",
        "\n",
        "- **GitHub Issues and Discussions**: For more technical support, users can open issues or participate in discussions directly on the [PyTorch Lightning GitHub repository](https://github.com/PyTorchLightning/pytorch-lightning). This is also where upcoming features and enhancements are discussed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DhUYVRG0Lxw8"
      },
      "id": "DhUYVRG0Lxw8"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "244b30e11b304ec68c4b64e4b8f051ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c1cd7937492468b80728072f9bf9a77",
              "IPY_MODEL_44be3743f9094f97b36f3eb6b3b2fd97",
              "IPY_MODEL_06a69b9ffe324bc5b596150d01a534ac"
            ],
            "layout": "IPY_MODEL_0c192f2541a24729a32d5bee92a7c788"
          }
        },
        "8c1cd7937492468b80728072f9bf9a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f266305f163404db0fbe1429a5915b2",
            "placeholder": "​",
            "style": "IPY_MODEL_e6efca63e89345228b115499cb50c5c7",
            "value": "Epoch 9: 100%"
          }
        },
        "44be3743f9094f97b36f3eb6b3b2fd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf21a94c86a458085787a700f9350b8",
            "max": 1875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_137c36098c694c7c806dc30b78343b1d",
            "value": 1875
          }
        },
        "06a69b9ffe324bc5b596150d01a534ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_431668fb199249a59a68fad4c42ebc40",
            "placeholder": "​",
            "style": "IPY_MODEL_ef698375ce0043deae326d3edc7acdda",
            "value": " 1875/1875 [00:41&lt;00:00, 45.37it/s, v_num=0]"
          }
        },
        "0c192f2541a24729a32d5bee92a7c788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4f266305f163404db0fbe1429a5915b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6efca63e89345228b115499cb50c5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf21a94c86a458085787a700f9350b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137c36098c694c7c806dc30b78343b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "431668fb199249a59a68fad4c42ebc40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef698375ce0043deae326d3edc7acdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aee519a1f974e1e81350b883cb1e858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2d114d91e3640259ab33c6cdf9e3bcf",
              "IPY_MODEL_6a65cbe7b0b941068f19451883137951",
              "IPY_MODEL_bd12648133ee4b6994587bdd931a364e"
            ],
            "layout": "IPY_MODEL_511eb6e3f9084f5d8a98fd61ca36172f"
          }
        },
        "a2d114d91e3640259ab33c6cdf9e3bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220042ab36ee45eb87b50d7fe3bde23d",
            "placeholder": "​",
            "style": "IPY_MODEL_ffc6e5dbb7ac4ee087ef7822e656702e",
            "value": "Epoch 1: 100%"
          }
        },
        "6a65cbe7b0b941068f19451883137951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff81928ba854ad0bb33f4f8385fbefb",
            "max": 1719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_899046eb149444b69c0e15b420d91af8",
            "value": 1719
          }
        },
        "bd12648133ee4b6994587bdd931a364e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ca4a2dde6b45088f9eaeefc072945c",
            "placeholder": "​",
            "style": "IPY_MODEL_3f36775917954b628a1fa55e4c314ff1",
            "value": " 1719/1719 [00:34&lt;00:00, 49.75it/s, v_num=2]"
          }
        },
        "511eb6e3f9084f5d8a98fd61ca36172f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "220042ab36ee45eb87b50d7fe3bde23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc6e5dbb7ac4ee087ef7822e656702e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff81928ba854ad0bb33f4f8385fbefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899046eb149444b69c0e15b420d91af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9ca4a2dde6b45088f9eaeefc072945c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f36775917954b628a1fa55e4c314ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}